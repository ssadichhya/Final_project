{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/27 10:19:08 WARN Utils: Your hostname, ubuntu-Lenovo-Legion-5-15ARH05 resolves to a loopback address: 127.0.1.1; using 172.16.5.112 instead (on interface wlp4s0)\n",
      "23/10/27 10:19:08 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "23/10/27 10:19:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/10/27 10:19:08 WARN DependencyUtils: Local jar /usr/lib/jvm/java-11-openjdk-amd64/lib/postgresql-42.5.0.jar does not exist, skipping.\n",
      "23/10/27 10:19:09 INFO SparkContext: Running Spark version 3.4.1\n",
      "23/10/27 10:19:09 INFO ResourceUtils: ==============================================================\n",
      "23/10/27 10:19:09 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
      "23/10/27 10:19:09 INFO ResourceUtils: ==============================================================\n",
      "23/10/27 10:19:09 INFO SparkContext: Submitted application: final_project\n",
      "23/10/27 10:19:09 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 2048, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "23/10/27 10:19:09 INFO ResourceProfile: Limiting resource is cpu\n",
      "23/10/27 10:19:09 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
      "23/10/27 10:19:09 INFO SecurityManager: Changing view acls to: ubuntu\n",
      "23/10/27 10:19:09 INFO SecurityManager: Changing modify acls to: ubuntu\n",
      "23/10/27 10:19:09 INFO SecurityManager: Changing view acls groups to: \n",
      "23/10/27 10:19:09 INFO SecurityManager: Changing modify acls groups to: \n",
      "23/10/27 10:19:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ubuntu; groups with view permissions: EMPTY; users with modify permissions: ubuntu; groups with modify permissions: EMPTY\n",
      "23/10/27 10:19:09 INFO Utils: Successfully started service 'sparkDriver' on port 40163.\n",
      "23/10/27 10:19:09 INFO SparkEnv: Registering MapOutputTracker\n",
      "23/10/27 10:19:09 INFO SparkEnv: Registering BlockManagerMaster\n",
      "23/10/27 10:19:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "23/10/27 10:19:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "23/10/27 10:19:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "23/10/27 10:19:09 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e04785b0-b699-4dde-bed9-a1221a3dc4c4\n",
      "23/10/27 10:19:09 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB\n",
      "23/10/27 10:19:09 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "23/10/27 10:19:09 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI\n",
      "23/10/27 10:19:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
      "23/10/27 10:19:10 ERROR SparkContext: Failed to add /usr/lib/jvm/java-11-openjdk-amd64/lib/postgresql-42.5.0.jar to Spark environment\n",
      "java.io.FileNotFoundException: Jar /usr/lib/jvm/java-11-openjdk-amd64/lib/postgresql-42.5.0.jar not found\n",
      "\tat org.apache.spark.SparkContext.addLocalJarFile$1(SparkContext.scala:1968)\n",
      "\tat org.apache.spark.SparkContext.addJar(SparkContext.scala:2023)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$12(SparkContext.scala:507)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$new$12$adapted(SparkContext.scala:507)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.SparkContext.<init>(SparkContext.scala:507)\n",
      "\tat org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:238)\n",
      "\tat py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "\tat py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "23/10/27 10:19:10 INFO Executor: Starting executor ID driver on host 172.16.5.112\n",
      "23/10/27 10:19:10 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''\n",
      "23/10/27 10:19:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41715.\n",
      "23/10/27 10:19:10 INFO NettyBlockTransferService: Server created on 172.16.5.112:41715\n",
      "23/10/27 10:19:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "23/10/27 10:19:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.16.5.112, 41715, None)\n",
      "23/10/27 10:19:10 INFO BlockManagerMasterEndpoint: Registering block manager 172.16.5.112:41715 with 434.4 MiB RAM, BlockManagerId(driver, 172.16.5.112, 41715, None)\n",
      "23/10/27 10:19:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.16.5.112, 41715, None)\n",
      "23/10/27 10:19:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.16.5.112, 41715, None)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"final_project\") \\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.executor.memory\", \"2g\")\\\n",
    "    .config(\"spark.jars\", \"/usr/lib/jvm/java-11-openjdk-amd64/lib/postgresql-42.5.0.jar\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = \"/home/ubuntu/Desktop/final_project/Raw_Data/job_descriptions.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/27 10:19:49 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "23/10/27 10:19:49 INFO SharedState: Warehouse path is 'file:/home/ubuntu/Desktop/final_project/ETL/spark-warehouse'.\n",
      "23/10/27 10:19:50 INFO InMemoryFileIndex: It took 54 ms to list leaf files for 1 paths.\n",
      "23/10/27 10:19:50 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.\n",
      "23/10/27 10:19:53 INFO FileSourceStrategy: Pushed Filters: \n",
      "23/10/27 10:19:53 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)\n",
      "23/10/27 10:19:53 INFO CodeGenerator: Code generated in 221.305194 ms\n",
      "23/10/27 10:19:53 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 200.2 KiB, free 434.2 MiB)\n",
      "23/10/27 10:19:53 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.6 KiB, free 434.2 MiB)\n",
      "23/10/27 10:19:53 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 172.16.5.112:41715 (size: 34.6 KiB, free: 434.4 MiB)\n",
      "23/10/27 10:19:53 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0\n",
      "23/10/27 10:19:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 109210027 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "23/10/27 10:19:54 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0\n",
      "23/10/27 10:19:54 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "23/10/27 10:19:54 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)\n",
      "23/10/27 10:19:54 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/10/27 10:19:54 INFO DAGScheduler: Missing parents: List()\n",
      "23/10/27 10:19:54 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/10/27 10:19:54 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.1 KiB, free 434.2 MiB)\n",
      "23/10/27 10:19:54 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 434.2 MiB)\n",
      "23/10/27 10:19:54 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 172.16.5.112:41715 (size: 6.0 KiB, free: 434.4 MiB)\n",
      "23/10/27 10:19:54 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1535\n",
      "23/10/27 10:19:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "23/10/27 10:19:54 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0\n",
      "23/10/27 10:19:54 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (172.16.5.112, executor driver, partition 0, PROCESS_LOCAL, 7951 bytes) \n",
      "23/10/27 10:19:54 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
      "23/10/27 10:19:54 INFO FileScanRDD: Reading File path: file:///home/ubuntu/Desktop/final_project/Raw_Data/job_descriptions.csv, range: 0-109210027, partition values: [empty row]\n",
      "23/10/27 10:19:54 INFO CodeGenerator: Code generated in 11.969226 ms\n",
      "23/10/27 10:19:54 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1840 bytes result sent to driver\n",
      "23/10/27 10:19:54 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 200 ms on 172.16.5.112 (executor driver) (1/1)\n",
      "23/10/27 10:19:54 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "23/10/27 10:19:54 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 0.336 s\n",
      "23/10/27 10:19:54 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/10/27 10:19:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished\n",
      "23/10/27 10:19:54 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 0.391478 s\n",
      "23/10/27 10:19:54 INFO CodeGenerator: Code generated in 9.771417 ms\n",
      "23/10/27 10:19:54 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 172.16.5.112:41715 in memory (size: 6.0 KiB, free: 434.4 MiB)\n",
      "23/10/27 10:19:54 INFO FileSourceStrategy: Pushed Filters: \n",
      "23/10/27 10:19:54 INFO FileSourceStrategy: Post-Scan Filters: \n",
      "23/10/27 10:19:54 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 200.2 KiB, free 434.0 MiB)\n",
      "23/10/27 10:19:54 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.6 KiB, free 433.9 MiB)\n",
      "23/10/27 10:19:54 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 172.16.5.112:41715 (size: 34.6 KiB, free: 434.3 MiB)\n",
      "23/10/27 10:19:54 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0\n",
      "23/10/27 10:19:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 109210027 bytes, open cost is considered as scanning 4194304 bytes.\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(csv, header=True, inferSchema=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+--------------+------------+--------------------+--------------------+--------+---------+---------+------------+----------------+----------+------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|          Job Id|   Experience|Qualifications|Salary Range|            location|             Country|latitude|longitude|Work Type|Company Size|Job Posting Date|Preference|    Contact Person|             Contact|           Job Title|                Role|         Job Portal|     Job Description|            Benefits|              skills|    Responsibilities|             Company|     Company Profile|\n",
      "+----------------+-------------+--------------+------------+--------------------+--------------------+--------+---------+---------+------------+----------------+----------+------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|1089843540111562|5 to 15 Years|        M.Tech|   $59K-$99K|             Douglas|         Isle of Man| 54.2361|  -4.5481|   Intern|       26801|      2022-04-24|    Female|Brandon Cunningham|001-381-930-7517x737|Digital Marketing...|Social Media Manager|           Snagajob|Social Media Mana...|{'Flexible Spendi...|Social media plat...|Manage and grow s...|   Icahn Enterprises|\"{\"\"Sector\"\":\"\"Di...|\n",
      "| 398454096642776|2 to 12 Years|           BCA|  $56K-$116K|            Ashgabat|        Turkmenistan| 38.9697|  59.5563|   Intern|      100340|      2022-12-19|    Female|  Francisco Larsen|        461-509-4216|       Web Developer|Frontend Web Deve...|           Idealist|Frontend Web Deve...|{'Health Insuranc...|HTML, CSS, JavaSc...|Design and code u...|PNC Financial Ser...|\"{\"\"Sector\"\":\"\"Fi...|\n",
      "| 481640072963533|0 to 12 Years|           PhD|  $61K-$104K|               Macao|    Macao SAR, China| 22.1987| 113.5439|Temporary|       84525|      2022-09-14|      Male|       Gary Gibson|          9687619505|  Operations Manager|Quality Control M...|       Jobs2Careers|Quality Control M...|{'Legal Assistanc...|Quality control p...|Establish and enf...|United Services A...|\"{\"\"Sector\"\":\"\"In...|\n",
      "| 688192671473044|4 to 11 Years|           PhD|   $65K-$91K|          Porto-Novo|               Benin|  9.3077|   2.3158|Full-Time|      129896|      2023-02-25|    Female|        Joy Lucero|+1-820-643-5431x4...|    Network Engineer|Wireless Network ...|           FlexJobs|Wireless Network ...|{'Transportation ...|Wireless network ...|Design, configure...|                Hess|\"{\"\"Sector\"\":\"\"En...|\n",
      "| 117057806156508|1 to 12 Years|           MBA|   $64K-$87K|            Santiago|               Chile|-35.6751| -71.5429|   Intern|       53944|      2022-10-11|    Female|     Julie Johnson|   343.975.4702x9340|       Event Manager|  Conference Manager|       Jobs2Careers|A Conference Mana...|{'Flexible Spendi...|Event planning Co...|Specialize in con...|        Cairn Energy|\"{\"\"Sector\"\":\"\"En...|\n",
      "| 116831420231957|4 to 12 Years|           MCA|   $59K-$93K|            Brussels|             Belgium| 50.5039|   4.4699|Full-Time|       23196|      2023-07-25|      Male|      Matthew Gill| (973)791-5355x52199|     Software Tester|Quality Assurance...|           Snagajob|A Quality Assuran...|{'Life and Disabi...|Quality assurance...|Test software app...|Adani Ports and S...|\"{\"\"Sector\"\":\"\"In...|\n",
      "|1292168246729889|3 to 15 Years|           PhD|  $63K-$103K|         George Town|      Cayman Islands| 19.3133| -81.2546|Temporary|       26119|      2023-04-10|      Both|    Zachary Hansen|001-268-510-4362x789|             Teacher|   Classroom Teacher|           FlexJobs|A Classroom Teach...|{'Flexible Spendi...|Teaching pedagogy...|Plan and deliver ...|               FedEx|\"{\"\"Sector\"\":\"\"Lo...|\n",
      "|1498778686197107| 2 to 8 Years|         M.Com|  $65K-$102K|          SÃ£o TomÃ©|Sao Tome and Prin...|  0.1864|   6.6131| Contract|       40558|      2022-09-20|    Female|   Chad Strickland|  667.202.6824x15893|      UX/UI Designer|User Interface De...|             Indeed|User Interface De...|{'Employee Assist...|UI design princip...|Create visually a...|        Ryder System|\"{\"\"Sector\"\":\"\"Tr...|\n",
      "|1680293940995740| 2 to 9 Years|           BBA|  $65K-$102K|                Male|            Maldives|  3.2028|  73.2207|Temporary|      105343|      2022-02-19|    Female|      David Hanson| +1-337-946-9956x550|      UX/UI Designer|Interaction Designer|             Indeed|Interaction Desig...|{'Transportation ...|Interaction desig...|Work on interacti...|Zee Entertainment...|\"{\"\"Sector\"\":\"\"Me...|\n",
      "| 255627812588102|1 to 10 Years|           BBA|   $60K-$80K|        Saint John's| Antigua and Barbuda| 17.0608| -61.7964|Full-Time|      102069|      2022-05-13|      Both|       John Nguyen|001-318-990-0531x978|     Wedding Planner|  Wedding Consultant|Stack Overflow Jobs|A Wedding Consult...|{'Legal Assistanc...|Wedding planning ...|Offer expert advi...|                 CSX|\"{\"\"Sector\"\":\"\"Tr...|\n",
      "|2696958764033354|3 to 10 Years|           BCA|  $57K-$104K|              Manama|             Bahrain| 26.0667|  50.5577| Contract|      130338|      2023-07-01|    Female|      John Collier|    001-683-879-1350|          QA Analyst|Performance Testi...|          Glassdoor|Performance Testi...|{'Flexible Spendi...|Performance testi...|Focus on performa...|          McDonald's|\"{\"\"Sector\"\":\"\"Fo...|\n",
      "|1446194141960546|4 to 12 Years|        B.Tech|   $64K-$98K|The City of Hamilton|             Bermuda| 32.3078| -64.7505| Contract|      117285|      2021-10-11|      Male|     Tammy Carroll|    001-388-421-1960| Litigation Attorney| Family Law Attorney|Stack Overflow Jobs|Family Law Attorn...|{'Employee Referr...|Family law Divorc...|Specialize in fam...|         TPG Telecom|\"{\"\"Sector\"\":\"\"Te...|\n",
      "|1914121205954296|3 to 15 Years|           MCA|  $65K-$122K|            Kingston|             Jamaica| 18.1096| -77.2975|Part-Time|       79071|      2022-01-17|      Both|   Jennifer Moreno|        200-851-9382| Mechanical Engineer|Mechanical Design...|Stack Overflow Jobs|Mechanical Design...|{'Tuition Reimbur...|Mechanical engine...|Design mechanical...|     ThyssenKrupp AG|\"{\"\"Sector\"\":\"\"Ma...|\n",
      "| 290761760113904| 1 to 8 Years|         B.Com|   $56K-$86K|              Banjul|              Gambia| 13.4432| -15.3101|Temporary|      127900|      2022-05-24|    Female|     Lisa Franklin|  (229)625-8850x6916|Network Administr...|Network Security ...|           FlexJobs|Protect an organi...|{'Legal Assistanc...|Network security ...|Manage and secure...|    EnLink Midstream|\"{\"\"Sector\"\":\"\"En...|\n",
      "|1627539131873813| 1 to 9 Years|           MCA|   $57K-$98K|            Damascus|Syrian Arab Republic| 34.8021|  38.9968|Full-Time|       92128|      2022-03-01|      Male|        Adam White|    001-805-834-6153|     Account Manager|Sales Account Man...|            USAJOBS|A Sales Account M...|{'Casual Dress Co...|Account managemen...|Manage sales acco...| NGL Energy Partners|\"{\"\"Sector\"\":\"\"En...|\n",
      "|2691974960988857|4 to 12 Years|         M.Com|  $65K-$100K|               Sanaa|               Yemen| 15.5527|  48.5164|Part-Time|       92028|      2023-08-25|      Male|    Michael Graham|    001-609-517-5993|       Brand Manager|Product Brand Man...|        SimplyHired|A Product Brand M...|{'Health Insuranc...|Product branding ...|Manage the brandi...|            Bayer AG|\"{\"\"Sector\"\":\"\"Ph...|\n",
      "|2823887164112482|5 to 14 Years|        M.Tech|   $60K-$83K|          San Marino|          San Marino| 43.9424|  12.4578|Part-Time|       49100|      2022-04-19|      Male|   Samuel Peterson|       (434)560-6482|       Social Worker|School Social Worker|          Glassdoor|Support students ...|{'Health Insuranc...|School social wor...|Collaborate with ...|               Deere|\"{\"\"Sector\"\":\"\"In...|\n",
      "|  76902098772934|0 to 11 Years|            BA|  $55K-$117K|             Papeete|    French Polynesia|-17.6797|-149.4068|Full-Time|       29318|      2022-05-18|      Male|    Benjamin Lopez| (331)668-1212x28407|Social Media Coor...|     Content Creator|       Jobs2Careers|Create engaging a...|{'Casual Dress Co...|Content creation ...|Create compelling...|Mondelez Internat...|\"{\"\"Sector\"\":\"\"Fo...|\n",
      "| 235216486127884|3 to 12 Years|            BA|  $55K-$121K|               Seoul|         North Korea| 40.3399| 127.5101| Contract|      126630|      2021-12-29|    Female|     Adam Anderson|    459-591-7982x348|Email Marketing S...|Deliverability An...|    Internships.com|Monitor and impro...|{'Employee Referr...|Email deliverabil...|Focus on email de...|                  3M|\"{\"\"Sector\"\":\"\"Co...|\n",
      "| 407980927519454| 5 to 9 Years|           PhD|  $65K-$128K|            Kinshasa|Democratic Republ...| -4.0383|  21.7587|Temporary|       48199|      2022-07-27|    Female|        Jason Cook|  (961)330-3515x6191|       HR Generalist|      HR Coordinator|           Snagajob|HR Coordinators a...|{'Health Insuranc...|Human resources R...|Assist with recru...|                 KKR|\"{\"\"Sector\"\":\"\"Fi...|\n",
      "+----------------+-------------+--------------+------------+--------------------+--------------------+--------+---------+---------+------------+----------------+----------+------------------+--------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/27 10:19:59 INFO FileSourceStrategy: Pushed Filters: \n",
      "23/10/27 10:19:59 INFO FileSourceStrategy: Post-Scan Filters: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[Job Id: string, Experience: string, Qualifications: string, Salary Range: string, location: string, Country: string, latitude: string, longitude: string, Work Type: string, Company Size: string, Job Posting Date: string, Preference: string, Contact Person: string, Contact: string, Job Title: string, Role: string, Job Portal: string, Job Description: string, Benefits: string, skills: string, Responsibilities: string, Company: string, Company Profile: string]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped = [\"Contact Person\", \"Contact\", \"Benefits\",\"Company Profile\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(*dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+--------------+------------+--------------------+--------------------+--------+---------+---------+------------+----------------+----------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|          Job Id|   Experience|Qualifications|Salary Range|            location|             Country|latitude|longitude|Work Type|Company Size|Job Posting Date|Preference|           Job Title|                Role|         Job Portal|     Job Description|              skills|    Responsibilities|             Company|\n",
      "+----------------+-------------+--------------+------------+--------------------+--------------------+--------+---------+---------+------------+----------------+----------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|1089843540111562|5 to 15 Years|        M.Tech|   $59K-$99K|             Douglas|         Isle of Man| 54.2361|  -4.5481|   Intern|       26801|      2022-04-24|    Female|Digital Marketing...|Social Media Manager|           Snagajob|Social Media Mana...|Social media plat...|Manage and grow s...|   Icahn Enterprises|\n",
      "| 398454096642776|2 to 12 Years|           BCA|  $56K-$116K|            Ashgabat|        Turkmenistan| 38.9697|  59.5563|   Intern|      100340|      2022-12-19|    Female|       Web Developer|Frontend Web Deve...|           Idealist|Frontend Web Deve...|HTML, CSS, JavaSc...|Design and code u...|PNC Financial Ser...|\n",
      "| 481640072963533|0 to 12 Years|           PhD|  $61K-$104K|               Macao|    Macao SAR, China| 22.1987| 113.5439|Temporary|       84525|      2022-09-14|      Male|  Operations Manager|Quality Control M...|       Jobs2Careers|Quality Control M...|Quality control p...|Establish and enf...|United Services A...|\n",
      "| 688192671473044|4 to 11 Years|           PhD|   $65K-$91K|          Porto-Novo|               Benin|  9.3077|   2.3158|Full-Time|      129896|      2023-02-25|    Female|    Network Engineer|Wireless Network ...|           FlexJobs|Wireless Network ...|Wireless network ...|Design, configure...|                Hess|\n",
      "| 117057806156508|1 to 12 Years|           MBA|   $64K-$87K|            Santiago|               Chile|-35.6751| -71.5429|   Intern|       53944|      2022-10-11|    Female|       Event Manager|  Conference Manager|       Jobs2Careers|A Conference Mana...|Event planning Co...|Specialize in con...|        Cairn Energy|\n",
      "| 116831420231957|4 to 12 Years|           MCA|   $59K-$93K|            Brussels|             Belgium| 50.5039|   4.4699|Full-Time|       23196|      2023-07-25|      Male|     Software Tester|Quality Assurance...|           Snagajob|A Quality Assuran...|Quality assurance...|Test software app...|Adani Ports and S...|\n",
      "|1292168246729889|3 to 15 Years|           PhD|  $63K-$103K|         George Town|      Cayman Islands| 19.3133| -81.2546|Temporary|       26119|      2023-04-10|      Both|             Teacher|   Classroom Teacher|           FlexJobs|A Classroom Teach...|Teaching pedagogy...|Plan and deliver ...|               FedEx|\n",
      "|1498778686197107| 2 to 8 Years|         M.Com|  $65K-$102K|          SÃ£o TomÃ©|Sao Tome and Prin...|  0.1864|   6.6131| Contract|       40558|      2022-09-20|    Female|      UX/UI Designer|User Interface De...|             Indeed|User Interface De...|UI design princip...|Create visually a...|        Ryder System|\n",
      "|1680293940995740| 2 to 9 Years|           BBA|  $65K-$102K|                Male|            Maldives|  3.2028|  73.2207|Temporary|      105343|      2022-02-19|    Female|      UX/UI Designer|Interaction Designer|             Indeed|Interaction Desig...|Interaction desig...|Work on interacti...|Zee Entertainment...|\n",
      "| 255627812588102|1 to 10 Years|           BBA|   $60K-$80K|        Saint John's| Antigua and Barbuda| 17.0608| -61.7964|Full-Time|      102069|      2022-05-13|      Both|     Wedding Planner|  Wedding Consultant|Stack Overflow Jobs|A Wedding Consult...|Wedding planning ...|Offer expert advi...|                 CSX|\n",
      "|2696958764033354|3 to 10 Years|           BCA|  $57K-$104K|              Manama|             Bahrain| 26.0667|  50.5577| Contract|      130338|      2023-07-01|    Female|          QA Analyst|Performance Testi...|          Glassdoor|Performance Testi...|Performance testi...|Focus on performa...|          McDonald's|\n",
      "|1446194141960546|4 to 12 Years|        B.Tech|   $64K-$98K|The City of Hamilton|             Bermuda| 32.3078| -64.7505| Contract|      117285|      2021-10-11|      Male| Litigation Attorney| Family Law Attorney|Stack Overflow Jobs|Family Law Attorn...|Family law Divorc...|Specialize in fam...|         TPG Telecom|\n",
      "|1914121205954296|3 to 15 Years|           MCA|  $65K-$122K|            Kingston|             Jamaica| 18.1096| -77.2975|Part-Time|       79071|      2022-01-17|      Both| Mechanical Engineer|Mechanical Design...|Stack Overflow Jobs|Mechanical Design...|Mechanical engine...|Design mechanical...|     ThyssenKrupp AG|\n",
      "| 290761760113904| 1 to 8 Years|         B.Com|   $56K-$86K|              Banjul|              Gambia| 13.4432| -15.3101|Temporary|      127900|      2022-05-24|    Female|Network Administr...|Network Security ...|           FlexJobs|Protect an organi...|Network security ...|Manage and secure...|    EnLink Midstream|\n",
      "|1627539131873813| 1 to 9 Years|           MCA|   $57K-$98K|            Damascus|Syrian Arab Republic| 34.8021|  38.9968|Full-Time|       92128|      2022-03-01|      Male|     Account Manager|Sales Account Man...|            USAJOBS|A Sales Account M...|Account managemen...|Manage sales acco...| NGL Energy Partners|\n",
      "|2691974960988857|4 to 12 Years|         M.Com|  $65K-$100K|               Sanaa|               Yemen| 15.5527|  48.5164|Part-Time|       92028|      2023-08-25|      Male|       Brand Manager|Product Brand Man...|        SimplyHired|A Product Brand M...|Product branding ...|Manage the brandi...|            Bayer AG|\n",
      "|2823887164112482|5 to 14 Years|        M.Tech|   $60K-$83K|          San Marino|          San Marino| 43.9424|  12.4578|Part-Time|       49100|      2022-04-19|      Male|       Social Worker|School Social Worker|          Glassdoor|Support students ...|School social wor...|Collaborate with ...|               Deere|\n",
      "|  76902098772934|0 to 11 Years|            BA|  $55K-$117K|             Papeete|    French Polynesia|-17.6797|-149.4068|Full-Time|       29318|      2022-05-18|      Male|Social Media Coor...|     Content Creator|       Jobs2Careers|Create engaging a...|Content creation ...|Create compelling...|Mondelez Internat...|\n",
      "| 235216486127884|3 to 12 Years|            BA|  $55K-$121K|               Seoul|         North Korea| 40.3399| 127.5101| Contract|      126630|      2021-12-29|    Female|Email Marketing S...|Deliverability An...|    Internships.com|Monitor and impro...|Email deliverabil...|Focus on email de...|                  3M|\n",
      "| 407980927519454| 5 to 9 Years|           PhD|  $65K-$128K|            Kinshasa|Democratic Republ...| -4.0383|  21.7587|Temporary|       48199|      2022-07-27|    Female|       HR Generalist|      HR Coordinator|           Snagajob|HR Coordinators a...|Human resources R...|Assist with recru...|                 KKR|\n",
      "+----------------+-------------+--------------+------------+--------------------+--------------------+--------+---------+---------+------------+----------------+----------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Job Id: string (nullable = true)\n",
      " |-- Experience: string (nullable = true)\n",
      " |-- Qualifications: string (nullable = true)\n",
      " |-- Salary Range: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      " |-- longitude: string (nullable = true)\n",
      " |-- Work Type: string (nullable = true)\n",
      " |-- Company Size: string (nullable = true)\n",
      " |-- Job Posting Date: string (nullable = true)\n",
      " |-- Preference: string (nullable = true)\n",
      " |-- Job Title: string (nullable = true)\n",
      " |-- Role: string (nullable = true)\n",
      " |-- Job Portal: string (nullable = true)\n",
      " |-- Job Description: string (nullable = true)\n",
      " |-- skills: string (nullable = true)\n",
      " |-- Responsibilities: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import LongType, FloatType, IntegerType, DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Job Id\", df[\"Job Id\"].cast(LongType()))\\\n",
    "        .withColumn(\"latitude\", df[\"latitude\"].cast(FloatType()))\\\n",
    "         .withColumn(\"longitude\", df[\"longitude\"].cast(FloatType()))\\\n",
    "          .withColumn(\"Company Size\", df[\"Company Size\"].cast(IntegerType()))\\\n",
    "           .withColumn(\"Job Posting Date\", df[\"Job Posting Date\"].cast(DateType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "import re\n",
    "\n",
    "def calculate_average(range_str):\n",
    "    # Use regular expression to extract numbers\n",
    "    numbers = re.findall(r'\\d+', range_str)\n",
    "    if len(numbers) == 2:\n",
    "        lower = int(numbers[0])\n",
    "        upper = int(numbers[1])\n",
    "        avg = (lower + upper) / 2\n",
    "        return avg\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "calculate_average_udf = F.udf(calculate_average)\n",
    "\n",
    "# Add a new column with the calculated average\n",
    "new_df = df.withColumn(\"Average\", calculate_average_udf(df[\"Salary Range\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Job Id: long (nullable = true)\n",
      " |-- Experience: string (nullable = true)\n",
      " |-- Qualifications: string (nullable = true)\n",
      " |-- Salary Range: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- latitude: float (nullable = true)\n",
      " |-- longitude: float (nullable = true)\n",
      " |-- Work Type: string (nullable = true)\n",
      " |-- Company Size: integer (nullable = true)\n",
      " |-- Job Posting Date: date (nullable = true)\n",
      " |-- Preference: string (nullable = true)\n",
      " |-- Job Title: string (nullable = true)\n",
      " |-- Role: string (nullable = true)\n",
      " |-- Job Portal: string (nullable = true)\n",
      " |-- Job Description: string (nullable = true)\n",
      " |-- skills: string (nullable = true)\n",
      " |-- Responsibilities: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Average Salary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.withColumnRenamed(\"Average\",\"Average Salary\").printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Resolved attribute(s) Salary Range#43 missing from Job Id#221L,Experience#41,Qualifications#42,Salary Range#1445,location#44,Country#45,latitude#241,longitude#261,Work Type#48,Company Size#281,Job Posting Date#301,Preference#51,Job Title#54,Role#55,Job Portal#56,Job Description#57,skills#59,Responsibilities#60,Company#61 in operator !Project [Job Id#221L, Experience#41, Qualifications#42, Salary Range#1445, location#44, Country#45, latitude#241, longitude#261, Work Type#48, Company Size#281, Job Posting Date#301, Preference#51, Job Title#54, Role#55, Job Portal#56, Job Description#57, skills#59, Responsibilities#60, Company#61, cast(split(Salary Range#43, -, -1)[0] as int) AS Min Salary#1465]. Attribute(s) with the same name appear in the operation: Salary Range. Please check if the right attribute(s) are used.;\n!Project [Job Id#221L, Experience#41, Qualifications#42, Salary Range#1445, location#44, Country#45, latitude#241, longitude#261, Work Type#48, Company Size#281, Job Posting Date#301, Preference#51, Job Title#54, Role#55, Job Portal#56, Job Description#57, skills#59, Responsibilities#60, Company#61, cast(split(Salary Range#43, -, -1)[0] as int) AS Min Salary#1465]\n+- Project [Job Id#221L, Experience#41, Qualifications#42, regexp_replace(Salary Range#43, [$,K], , 1) AS Salary Range#1445, location#44, Country#45, latitude#241, longitude#261, Work Type#48, Company Size#281, Job Posting Date#301, Preference#51, Job Title#54, Role#55, Job Portal#56, Job Description#57, skills#59, Responsibilities#60, Company#61]\n   +- Project [Job Id#221L, Experience#41, Qualifications#42, Salary Range#43, location#44, Country#45, latitude#241, longitude#261, Work Type#48, Company Size#281, cast(Job Posting Date#50 as date) AS Job Posting Date#301, Preference#51, Job Title#54, Role#55, Job Portal#56, Job Description#57, skills#59, Responsibilities#60, Company#61]\n      +- Project [Job Id#221L, Experience#41, Qualifications#42, Salary Range#43, location#44, Country#45, latitude#241, longitude#261, Work Type#48, cast(Company Size#49 as int) AS Company Size#281, Job Posting Date#50, Preference#51, Job Title#54, Role#55, Job Portal#56, Job Description#57, skills#59, Responsibilities#60, Company#61]\n         +- Project [Job Id#221L, Experience#41, Qualifications#42, Salary Range#43, location#44, Country#45, latitude#241, cast(longitude#47 as float) AS longitude#261, Work Type#48, Company Size#49, Job Posting Date#50, Preference#51, Job Title#54, Role#55, Job Portal#56, Job Description#57, skills#59, Responsibilities#60, Company#61]\n            +- Project [Job Id#221L, Experience#41, Qualifications#42, Salary Range#43, location#44, Country#45, cast(latitude#46 as float) AS latitude#241, longitude#47, Work Type#48, Company Size#49, Job Posting Date#50, Preference#51, Job Title#54, Role#55, Job Portal#56, Job Description#57, skills#59, Responsibilities#60, Company#61]\n               +- Project [cast(Job Id#40 as bigint) AS Job Id#221L, Experience#41, Qualifications#42, Salary Range#43, location#44, Country#45, latitude#46, longitude#47, Work Type#48, Company Size#49, Job Posting Date#50, Preference#51, Job Title#54, Role#55, Job Portal#56, Job Description#57, skills#59, Responsibilities#60, Company#61]\n                  +- Project [Job Id#40, Experience#41, Qualifications#42, Salary Range#43, location#44, Country#45, latitude#46, longitude#47, Work Type#48, Company Size#49, Job Posting Date#50, Preference#51, Job Title#54, Role#55, Job Portal#56, Job Description#57, skills#59, Responsibilities#60, Company#61]\n                     +- Relation [Job Id#40,Experience#41,Qualifications#42,Salary Range#43,location#44,Country#45,latitude#46,longitude#47,Work Type#48,Company Size#49,Job Posting Date#50,Preference#51,Contact Person#52,Contact#53,Job Title#54,Role#55,Job Portal#56,Job Description#57,Benefits#58,skills#59,Responsibilities#60,Company#61,Company Profile#62] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m split_col \u001b[39m=\u001b[39m split(df[\u001b[39m\"\u001b[39m\u001b[39mSalary Range\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[39m# Extract minimum and maximum salary values and calculate the average\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m new_new_df \u001b[39m=\u001b[39m new_new_df\u001b[39m.\u001b[39;49mwithColumn(\u001b[39m\"\u001b[39;49m\u001b[39mMin Salary\u001b[39;49m\u001b[39m\"\u001b[39;49m, split_col\u001b[39m.\u001b[39;49mgetItem(\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mcast(\u001b[39m\"\u001b[39;49m\u001b[39mint\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m     10\u001b[0m new_new_df \u001b[39m=\u001b[39m new_new_df\u001b[39m.\u001b[39mwithColumn(\u001b[39m\"\u001b[39m\u001b[39mMax Salary\u001b[39m\u001b[39m\"\u001b[39m, split_col\u001b[39m.\u001b[39mgetItem(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcast(\u001b[39m\"\u001b[39m\u001b[39mint\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m     11\u001b[0m new_new_df \u001b[39m=\u001b[39m new_new_df\u001b[39m.\u001b[39mwithColumn(\u001b[39m\"\u001b[39m\u001b[39mAverage Salary\u001b[39m\u001b[39m\"\u001b[39m, (col(\u001b[39m\"\u001b[39m\u001b[39mMin Salary\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m col(\u001b[39m\"\u001b[39m\u001b[39mMax Salary\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/final_project/venv/lib/python3.10/site-packages/pyspark/sql/dataframe.py:5170\u001b[0m, in \u001b[0;36mDataFrame.withColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   5165\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(col, Column):\n\u001b[1;32m   5166\u001b[0m     \u001b[39mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m   5167\u001b[0m         error_class\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNOT_COLUMN\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   5168\u001b[0m         message_parameters\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39marg_name\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mcol\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39marg_type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mtype\u001b[39m(col)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m   5169\u001b[0m     )\n\u001b[0;32m-> 5170\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrame(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mwithColumn(colName, col\u001b[39m.\u001b[39;49m_jc), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m~/Desktop/final_project/venv/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/final_project/venv/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    181\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    183\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Resolved attribute(s) Salary Range#43 missing from Job Id#221L,Experience#41,Qualifications#42,Salary Range#1445,location#44,Country#45,latitude#241,longitude#261,Work Type#48,Company Size#281,Job Posting Date#301,Preference#51,Job Title#54,Role#55,Job Portal#56,Job Description#57,skills#59,Responsibilities#60,Company#61 in operator !Project [Job Id#221L, Experience#41, Qualifications#42, Salary Range#1445, location#44, Country#45, latitude#241, longitude#261, Work Type#48, Company Size#281, Job Posting Date#301, Preference#51, Job Title#54, Role#55, Job Portal#56, Job Description#57, skills#59, Responsibilities#60, Company#61, cast(split(Salary Range#43, -, -1)[0] as int) AS Min Salary#1465]. Attribute(s) with the same name appear in the operation: Salary Range. Please check if the right attribute(s) are used.;\n!Project [Job Id#221L, Experience#41, Qualifications#42, Salary Range#1445, location#44, Country#45, latitude#241, longitude#261, Work Type#48, Company Size#281, Job Posting Date#301, Preference#51, Job Title#54, Role#55, Job Portal#56, Job Description#57, skills#59, Responsibilities#60, Company#61, cast(split(Salary Range#43, -, -1)[0] as int) AS Min Salary#1465]\n+- Project [Job Id#221L, Experience#41, Qualifications#42, regexp_replace(Salary Range#43, [$,K], , 1) AS Salary Range#1445, location#44, Country#45, latitude#241, longitude#261, Work Type#48, Company Size#281, Job Posting Date#301, Preference#51, Job Title#54, Role#55, Job Portal#56, Job Description#57, skills#59, Responsibilities#60, Company#61]\n   +- Project [Job Id#221L, Experience#41, Qualifications#42, Salary Range#43, location#44, Country#45, latitude#241, longitude#261, Work Type#48, Company Size#281, cast(Job Posting Date#50 as date) AS Job Posting Date#301, Preference#51, Job Title#54, Role#55, Job Portal#56, Job Description#57, skills#59, Responsibilities#60, Company#61]\n      +- Project [Job Id#221L, Experience#41, Qualifications#42, Salary Range#43, location#44, Country#45, latitude#241, longitude#261, Work Type#48, cast(Company Size#49 as int) AS Company Size#281, Job Posting Date#50, Preference#51, Job Title#54, Role#55, Job Portal#56, Job Description#57, skills#59, Responsibilities#60, Company#61]\n         +- Project [Job Id#221L, Experience#41, Qualifications#42, Salary Range#43, location#44, Country#45, latitude#241, cast(longitude#47 as float) AS longitude#261, Work Type#48, Company Size#49, Job Posting Date#50, Preference#51, Job Title#54, Role#55, Job Portal#56, Job Description#57, skills#59, Responsibilities#60, Company#61]\n            +- Project [Job Id#221L, Experience#41, Qualifications#42, Salary Range#43, location#44, Country#45, cast(latitude#46 as float) AS latitude#241, longitude#47, Work Type#48, Company Size#49, Job Posting Date#50, Preference#51, Job Title#54, Role#55, Job Portal#56, Job Description#57, skills#59, Responsibilities#60, Company#61]\n               +- Project [cast(Job Id#40 as bigint) AS Job Id#221L, Experience#41, Qualifications#42, Salary Range#43, location#44, Country#45, latitude#46, longitude#47, Work Type#48, Company Size#49, Job Posting Date#50, Preference#51, Job Title#54, Role#55, Job Portal#56, Job Description#57, skills#59, Responsibilities#60, Company#61]\n                  +- Project [Job Id#40, Experience#41, Qualifications#42, Salary Range#43, location#44, Country#45, latitude#46, longitude#47, Work Type#48, Company Size#49, Job Posting Date#50, Preference#51, Job Title#54, Role#55, Job Portal#56, Job Description#57, skills#59, Responsibilities#60, Company#61]\n                     +- Relation [Job Id#40,Experience#41,Qualifications#42,Salary Range#43,location#44,Country#45,latitude#46,longitude#47,Work Type#48,Company Size#49,Job Posting Date#50,Preference#51,Contact Person#52,Contact#53,Job Title#54,Role#55,Job Portal#56,Job Description#57,Benefits#58,skills#59,Responsibilities#60,Company#61,Company Profile#62] csv\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.sql.functions import regexp_replace, split, col\n",
    "\n",
    "# # Assuming you have a DataFrame 'df' with a 'Salary Range' column\n",
    "# # Remove the '$' sign and split the range into two columns\n",
    "# new_new_df = df.withColumn(\"Salary Range\", regexp_replace(\"Salary Range\", \"[$,K]\", \"\"))\n",
    "# split_col = split(df[\"Salary Range\"], \"-\")\n",
    "\n",
    "# # Extract minimum and maximum salary values and calculate the average\n",
    "# new_new_df = new_new_df.withColumn(\"Min Salary\", split_col.getItem(0).cast(\"int\"))\n",
    "# new_new_df = new_new_df.withColumn(\"Max Salary\", split_col.getItem(1).cast(\"int\"))\n",
    "# new_new_df = new_new_df.withColumn(\"Average Salary\", (col(\"Min Salary\") + col(\"Max Salary\")) / 2)\n",
    "\n",
    "# # Show the updated DataFrame\n",
    "# new_new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/27 10:25:39 INFO SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0\n",
      "23/10/27 10:25:39 INFO DAGScheduler: Got job 2 (save at NativeMethodAccessorImpl.java:0) with 16 output partitions\n",
      "23/10/27 10:25:39 INFO DAGScheduler: Final stage: ResultStage 2 (save at NativeMethodAccessorImpl.java:0)\n",
      "23/10/27 10:25:39 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/10/27 10:25:39 INFO DAGScheduler: Missing parents: List()\n",
      "23/10/27 10:25:39 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[31] at save at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "23/10/27 10:25:39 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 55.0 KiB, free 177.2 MiB)\n",
      "23/10/27 10:25:39 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 23.1 KiB, free 177.2 MiB)\n",
      "23/10/27 10:25:39 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 172.16.5.112:41715 (size: 23.1 KiB, free: 177.5 MiB)\n",
      "23/10/27 10:25:39 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1535\n",
      "23/10/27 10:25:39 INFO DAGScheduler: Submitting 16 missing tasks from ResultStage 2 (MapPartitionsRDD[31] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
      "23/10/27 10:25:39 INFO TaskSchedulerImpl: Adding task set 2.0 with 16 tasks resource profile 0\n",
      "23/10/27 10:25:39 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 17) (172.16.5.112, executor driver, partition 0, PROCESS_LOCAL, 7951 bytes) \n",
      "23/10/27 10:25:39 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 18) (172.16.5.112, executor driver, partition 1, PROCESS_LOCAL, 7951 bytes) \n",
      "23/10/27 10:25:39 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 19) (172.16.5.112, executor driver, partition 2, PROCESS_LOCAL, 7951 bytes) \n",
      "23/10/27 10:25:39 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 20) (172.16.5.112, executor driver, partition 3, PROCESS_LOCAL, 7951 bytes) \n",
      "23/10/27 10:25:39 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 21) (172.16.5.112, executor driver, partition 4, PROCESS_LOCAL, 7951 bytes) \n",
      "23/10/27 10:25:39 INFO TaskSetManager: Starting task 5.0 in stage 2.0 (TID 22) (172.16.5.112, executor driver, partition 5, PROCESS_LOCAL, 7951 bytes) \n",
      "23/10/27 10:25:39 INFO TaskSetManager: Starting task 6.0 in stage 2.0 (TID 23) (172.16.5.112, executor driver, partition 6, PROCESS_LOCAL, 7951 bytes) \n",
      "23/10/27 10:25:39 INFO TaskSetManager: Starting task 7.0 in stage 2.0 (TID 24) (172.16.5.112, executor driver, partition 7, PROCESS_LOCAL, 7951 bytes) \n",
      "23/10/27 10:25:39 INFO TaskSetManager: Starting task 8.0 in stage 2.0 (TID 25) (172.16.5.112, executor driver, partition 8, PROCESS_LOCAL, 7951 bytes) \n",
      "23/10/27 10:25:39 INFO TaskSetManager: Starting task 9.0 in stage 2.0 (TID 26) (172.16.5.112, executor driver, partition 9, PROCESS_LOCAL, 7951 bytes) \n",
      "23/10/27 10:25:39 INFO TaskSetManager: Starting task 10.0 in stage 2.0 (TID 27) (172.16.5.112, executor driver, partition 10, PROCESS_LOCAL, 7951 bytes) \n",
      "23/10/27 10:25:39 INFO TaskSetManager: Starting task 11.0 in stage 2.0 (TID 28) (172.16.5.112, executor driver, partition 11, PROCESS_LOCAL, 7951 bytes) \n",
      "23/10/27 10:25:39 INFO TaskSetManager: Starting task 12.0 in stage 2.0 (TID 29) (172.16.5.112, executor driver, partition 12, PROCESS_LOCAL, 7951 bytes) \n",
      "23/10/27 10:25:39 INFO TaskSetManager: Starting task 13.0 in stage 2.0 (TID 30) (172.16.5.112, executor driver, partition 13, PROCESS_LOCAL, 7951 bytes) \n",
      "23/10/27 10:25:39 INFO TaskSetManager: Starting task 14.0 in stage 2.0 (TID 31) (172.16.5.112, executor driver, partition 14, PROCESS_LOCAL, 7951 bytes) \n",
      "23/10/27 10:25:39 INFO TaskSetManager: Starting task 15.0 in stage 2.0 (TID 32) (172.16.5.112, executor driver, partition 15, PROCESS_LOCAL, 7951 bytes) \n",
      "23/10/27 10:25:39 INFO Executor: Running task 1.0 in stage 2.0 (TID 18)\n",
      "23/10/27 10:25:39 INFO Executor: Running task 0.0 in stage 2.0 (TID 17)\n",
      "23/10/27 10:25:39 INFO Executor: Running task 3.0 in stage 2.0 (TID 20)\n",
      "23/10/27 10:25:39 INFO Executor: Running task 2.0 in stage 2.0 (TID 19)\n",
      "23/10/27 10:25:39 INFO Executor: Running task 5.0 in stage 2.0 (TID 22)\n",
      "23/10/27 10:25:39 INFO Executor: Running task 4.0 in stage 2.0 (TID 21)\n",
      "23/10/27 10:25:39 INFO Executor: Running task 7.0 in stage 2.0 (TID 24)\n",
      "23/10/27 10:25:39 INFO Executor: Running task 8.0 in stage 2.0 (TID 25)\n",
      "23/10/27 10:25:39 INFO Executor: Running task 6.0 in stage 2.0 (TID 23)\n",
      "23/10/27 10:25:39 INFO Executor: Running task 10.0 in stage 2.0 (TID 27)\n",
      "23/10/27 10:25:39 INFO Executor: Running task 9.0 in stage 2.0 (TID 26)\n",
      "23/10/27 10:25:39 INFO Executor: Running task 12.0 in stage 2.0 (TID 29)\n",
      "23/10/27 10:25:39 INFO Executor: Running task 11.0 in stage 2.0 (TID 28)\n",
      "23/10/27 10:25:39 INFO Executor: Running task 13.0 in stage 2.0 (TID 30)\n",
      "23/10/27 10:25:39 INFO Executor: Running task 14.0 in stage 2.0 (TID 31)\n",
      "23/10/27 10:25:39 INFO Executor: Running task 15.0 in stage 2.0 (TID 32)\n",
      "23/10/27 10:25:39 INFO BlockManager: Found block rdd_13_9 locally\n",
      "23/10/27 10:25:39 INFO BlockManager: Found block rdd_13_5 locally\n",
      "23/10/27 10:25:39 INFO BlockManager: Found block rdd_13_12 locally\n",
      "23/10/27 10:25:39 INFO BlockManager: Found block rdd_13_10 locally\n",
      "23/10/27 10:25:39 INFO BlockManager: Found block rdd_13_11 locally\n",
      "23/10/27 10:25:39 INFO BlockManager: Found block rdd_13_1 locally\n",
      "23/10/27 10:25:39 INFO BlockManager: Found block rdd_13_0 locally\n",
      "23/10/27 10:25:39 INFO BlockManager: Found block rdd_13_6 locally\n",
      "23/10/27 10:25:39 INFO BlockManager: Found block rdd_13_14 locally\n",
      "23/10/27 10:25:39 INFO BlockManager: Found block rdd_13_2 locally\n",
      "23/10/27 10:25:39 INFO BlockManager: Found block rdd_13_13 locally\n",
      "23/10/27 10:25:39 INFO BlockManager: Found block rdd_13_8 locally\n",
      "23/10/27 10:25:39 INFO BlockManager: Found block rdd_13_4 locally\n",
      "23/10/27 10:25:39 INFO BlockManager: Found block rdd_13_7 locally\n",
      "23/10/27 10:25:39 INFO BlockManager: Found block rdd_13_15 locally\n",
      "23/10/27 10:25:39 INFO BlockManager: Found block rdd_13_3 locally\n",
      "23/10/27 10:25:39 INFO TaskMemoryManager: Memory used in task 21\n",
      "23/10/27 10:25:39 INFO TaskMemoryManager: Acquired by HybridRowQueue(org.apache.spark.memory.TaskMemoryManager@189fb6db,/tmp/spark-e8ebaae7-6c2d-4ba7-be73-422f16cbaebc,19,org.apache.spark.serializer.SerializerManager@469496f6): 18.0 MiB\n",
      "23/10/27 10:25:39 INFO TaskMemoryManager: 0 bytes of memory were used by task 21 but are not associated with specific consumers\n",
      "23/10/27 10:25:39 INFO TaskMemoryManager: 93321840 bytes of memory are used for execution and 269736984 bytes of memory are used for storage\n",
      "23/10/27 10:25:39 INFO TaskMemoryManager: Memory used in task 24\n",
      "23/10/27 10:25:39 INFO TaskMemoryManager: Acquired by HybridRowQueue(org.apache.spark.memory.TaskMemoryManager@61662a81,/tmp/spark-e8ebaae7-6c2d-4ba7-be73-422f16cbaebc,19,org.apache.spark.serializer.SerializerManager@469496f6): 14.0 MiB\n",
      "23/10/27 10:25:39 INFO TaskMemoryManager: 0 bytes of memory were used by task 24 but are not associated with specific consumers\n",
      "23/10/27 10:25:39 INFO TaskMemoryManager: 103807440 bytes of memory are used for execution and 269736984 bytes of memory are used for storage\n",
      "23/10/27 10:25:39 INFO TaskMemoryManager: Memory used in task 26  (0 + 16) / 16]\n",
      "23/10/27 10:25:39 INFO TaskMemoryManager: Acquired by HybridRowQueue(org.apache.spark.memory.TaskMemoryManager@376afd9f,/tmp/spark-e8ebaae7-6c2d-4ba7-be73-422f16cbaebc,19,org.apache.spark.serializer.SerializerManager@469496f6): 13.6 MiB\n",
      "23/10/27 10:25:39 INFO TaskMemoryManager: Memory used in task 31\n",
      "23/10/27 10:25:39 INFO TaskMemoryManager: Acquired by HybridRowQueue(org.apache.spark.memory.TaskMemoryManager@61cd772,/tmp/spark-e8ebaae7-6c2d-4ba7-be73-422f16cbaebc,19,org.apache.spark.serializer.SerializerManager@469496f6): 13.6 MiB\n",
      "23/10/27 10:25:39 INFO TaskMemoryManager: 0 bytes of memory were used by task 31 but are not associated with specific consumers\n",
      "23/10/27 10:25:39 INFO TaskMemoryManager: 145907558 bytes of memory are used for execution and 269736984 bytes of memory are used for storage\n",
      "23/10/27 10:25:39 INFO TaskMemoryManager: 0 bytes of memory were used by task 26 but are not associated with specific consumers\n",
      "23/10/27 10:25:39 INFO TaskMemoryManager: 149053238 bytes of memory are used for execution and 269736984 bytes of memory are used for storage\n",
      "23/10/27 10:25:40 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 172.16.5.112:41715 in memory (size: 23.1 KiB, free: 177.5 MiB)\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: Memory used in task 32\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: Acquired by HybridRowQueue(org.apache.spark.memory.TaskMemoryManager@33bebf40,/tmp/spark-e8ebaae7-6c2d-4ba7-be73-422f16cbaebc,19,org.apache.spark.serializer.SerializerManager@469496f6): 7.0 MiB\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: Memory used in task 19\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: Acquired by HybridRowQueue(org.apache.spark.memory.TaskMemoryManager@3f3c4466,/tmp/spark-e8ebaae7-6c2d-4ba7-be73-422f16cbaebc,19,org.apache.spark.serializer.SerializerManager@469496f6): 12.0 MiB\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: Memory used in task 28\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: Acquired by HybridRowQueue(org.apache.spark.memory.TaskMemoryManager@392117a6,/tmp/spark-e8ebaae7-6c2d-4ba7-be73-422f16cbaebc,19,org.apache.spark.serializer.SerializerManager@469496f6): 8.0 MiB\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: Memory used in task 22\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: Memory used in task 25\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: Acquired by HybridRowQueue(org.apache.spark.memory.TaskMemoryManager@2b5159fd,/tmp/spark-e8ebaae7-6c2d-4ba7-be73-422f16cbaebc,19,org.apache.spark.serializer.SerializerManager@469496f6): 12.0 MiB\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: Acquired by HybridRowQueue(org.apache.spark.memory.TaskMemoryManager@22c22270,/tmp/spark-e8ebaae7-6c2d-4ba7-be73-422f16cbaebc,19,org.apache.spark.serializer.SerializerManager@469496f6): 8.0 MiB\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: Memory used in task 29\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: Acquired by HybridRowQueue(org.apache.spark.memory.TaskMemoryManager@55fd2b5f,/tmp/spark-e8ebaae7-6c2d-4ba7-be73-422f16cbaebc,19,org.apache.spark.serializer.SerializerManager@469496f6): 11.0 MiB\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: 0 bytes of memory were used by task 29 but are not associated with specific consumers\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: 185844455 bytes of memory are used for execution and 269656959 bytes of memory are used for storage\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: Memory used in task 18\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: Acquired by HybridRowQueue(org.apache.spark.memory.TaskMemoryManager@6802e6f7,/tmp/spark-e8ebaae7-6c2d-4ba7-be73-422f16cbaebc,19,org.apache.spark.serializer.SerializerManager@469496f6): 11.0 MiB\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: 0 bytes of memory were used by task 18 but are not associated with specific consumers\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: 185844455 bytes of memory are used for execution and 269656959 bytes of memory are used for storage\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: 0 bytes of memory were used by task 25 but are not associated with specific consumers\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: 0 bytes of memory were used by task 22 but are not associated with specific consumers\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: 0 bytes of memory were used by task 28 but are not associated with specific consumers\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: Memory used in task 30\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: 184795895 bytes of memory are used for execution and 269656959 bytes of memory are used for storage\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: 184795895 bytes of memory are used for execution and 269656959 bytes of memory are used for storage\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: Acquired by HybridRowQueue(org.apache.spark.memory.TaskMemoryManager@66cc46b9,/tmp/spark-e8ebaae7-6c2d-4ba7-be73-422f16cbaebc,19,org.apache.spark.serializer.SerializerManager@469496f6): 10.0 MiB\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: 0 bytes of memory were used by task 30 but are not associated with specific consumers\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: 0 bytes of memory were used by task 19 but are not associated with specific consumers\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: 184795895 bytes of memory are used for execution and 269656959 bytes of memory are used for storage\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: 0 bytes of memory were used by task 32 but are not associated with specific consumers\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: 184795895 bytes of memory are used for execution and 269656959 bytes of memory are used for storage\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: Memory used in task 20\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: Memory used in task 27\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: Acquired by HybridRowQueue(org.apache.spark.memory.TaskMemoryManager@458c46b6,/tmp/spark-e8ebaae7-6c2d-4ba7-be73-422f16cbaebc,19,org.apache.spark.serializer.SerializerManager@469496f6): 10.0 MiB\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: 0 bytes of memory were used by task 20 but are not associated with specific consumers\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: 185844455 bytes of memory are used for execution and 269656959 bytes of memory are used for storage\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: Memory used in task 17\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: Acquired by HybridRowQueue(org.apache.spark.memory.TaskMemoryManager@40f08af5,/tmp/spark-e8ebaae7-6c2d-4ba7-be73-422f16cbaebc,19,org.apache.spark.serializer.SerializerManager@469496f6): 13.0 MiB\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: 0 bytes of memory were used by task 17 but are not associated with specific consumers\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: 185844455 bytes of memory are used for execution and 269656959 bytes of memory are used for storage\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: 184795895 bytes of memory are used for execution and 269656959 bytes of memory are used for storage\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: 185844455 bytes of memory are used for execution and 269656959 bytes of memory are used for storage\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: Acquired by HybridRowQueue(org.apache.spark.memory.TaskMemoryManager@3ae9f81a,/tmp/spark-e8ebaae7-6c2d-4ba7-be73-422f16cbaebc,19,org.apache.spark.serializer.SerializerManager@469496f6): 10.1 MiB\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: 0 bytes of memory were used by task 27 but are not associated with specific consumers\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: 183747335 bytes of memory are used for execution and 269656959 bytes of memory are used for storage\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: Memory used in task 23\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: Acquired by HybridRowQueue(org.apache.spark.memory.TaskMemoryManager@1ab4a6eb,/tmp/spark-e8ebaae7-6c2d-4ba7-be73-422f16cbaebc,19,org.apache.spark.serializer.SerializerManager@469496f6): 13.6 MiB\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: 0 bytes of memory were used by task 23 but are not associated with specific consumers\n",
      "23/10/27 10:25:40 INFO TaskMemoryManager: 183301914 bytes of memory are used for execution and 269656959 bytes of memory are used for storage\n",
      "23/10/27 10:25:56 INFO PythonUDFRunner: Times: total = 3415, boot = 356, init = 296, finish = 2763\n",
      "23/10/27 10:25:56 INFO Executor: Finished task 15.0 in stage 2.0 (TID 32). 2216 bytes result sent to driver\n",
      "23/10/27 10:25:56 INFO TaskSetManager: Finished task 15.0 in stage 2.0 (TID 32) in 16897 ms on 172.16.5.112 (executor driver) (1/16)\n",
      "23/10/27 10:25:56 INFO PythonUDFRunner: Times: total = 3127, boot = 49, init = 168, finish = 2910\n",
      "23/10/27 10:25:56 INFO PythonUDFRunner: Times: total = 3608, boot = 66, init = 324, finish = 3218\n",
      "23/10/27 10:25:56 INFO Executor: Finished task 14.0 in stage 2.0 (TID 31). 2173 bytes result sent to driver\n",
      "23/10/27 10:25:56 INFO TaskSetManager: Finished task 14.0 in stage 2.0 (TID 31) in 17026 ms on 172.16.5.112 (executor driver) (2/16)\n",
      "23/10/27 10:25:56 INFO Executor: Finished task 5.0 in stage 2.0 (TID 22). 2173 bytes result sent to driver\n",
      "23/10/27 10:25:56 INFO PythonUDFRunner: Times: total = 3506, boot = 31, init = 380, finish = 3095\n",
      "23/10/27 10:25:56 INFO TaskSetManager: Finished task 5.0 in stage 2.0 (TID 22) in 17072 ms on 172.16.5.112 (executor driver) (3/16)\n",
      "23/10/27 10:25:56 INFO Executor: Finished task 0.0 in stage 2.0 (TID 17). 2173 bytes result sent to driver\n",
      "23/10/27 10:25:56 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 17) in 17116 ms on 172.16.5.112 (executor driver) (4/16)\n",
      "23/10/27 10:25:56 INFO PythonUDFRunner: Times: total = 3652, boot = 97, init = 207, finish = 3348\n",
      "23/10/27 10:25:56 INFO PythonUDFRunner: Times: total = 3306, boot = 202, init = 420, finish = 2684\n",
      "23/10/27 10:25:56 INFO PythonUDFRunner: Times: total = 3466, boot = 12, init = 126, finish = 3328\n",
      "23/10/27 10:25:56 INFO Executor: Finished task 2.0 in stage 2.0 (TID 19). 2173 bytes result sent to driver\n",
      "23/10/27 10:25:56 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 19) in 17156 ms on 172.16.5.112 (executor driver) (5/16)\n",
      "23/10/27 10:25:56 INFO Executor: Finished task 8.0 in stage 2.0 (TID 25). 2173 bytes result sent to driver\n",
      "23/10/27 10:25:56 INFO TaskSetManager: Finished task 8.0 in stage 2.0 (TID 25) in 17177 ms on 172.16.5.112 (executor driver) (6/16)\n",
      "23/10/27 10:25:56 INFO Executor: Finished task 9.0 in stage 2.0 (TID 26). 2173 bytes result sent to driver\n",
      "23/10/27 10:25:56 INFO TaskSetManager: Finished task 9.0 in stage 2.0 (TID 26) in 17181 ms on 172.16.5.112 (executor driver) (7/16)\n",
      "23/10/27 10:25:56 INFO PythonUDFRunner: Times: total = 3359, boot = 174, init = 395, finish = 2790\n",
      "23/10/27 10:25:56 INFO PythonUDFRunner: Times: total = 2661, boot = 11, init = 119, finish = 2531\n",
      "23/10/27 10:25:56 INFO Executor: Finished task 10.0 in stage 2.0 (TID 27). 2173 bytes result sent to driver\n",
      "23/10/27 10:25:56 INFO TaskSetManager: Finished task 10.0 in stage 2.0 (TID 27) in 17226 ms on 172.16.5.112 (executor driver) (8/16)\n",
      "23/10/27 10:25:56 INFO PythonUDFRunner: Times: total = 2991, boot = 23, init = 139, finish = 2829\n",
      "23/10/27 10:25:56 INFO PythonUDFRunner: Times: total = 3206, boot = 158, init = 271, finish = 2777\n",
      "23/10/27 10:25:56 INFO PythonUDFRunner: Times: total = 3572, boot = 111, init = 231, finish = 3230\n",
      "23/10/27 10:25:56 INFO PythonUDFRunner: Times: total = 3345, boot = 330, init = 284, finish = 2731\n",
      "23/10/27 10:25:56 INFO Executor: Finished task 7.0 in stage 2.0 (TID 24). 2173 bytes result sent to driver\n",
      "23/10/27 10:25:56 INFO TaskSetManager: Finished task 7.0 in stage 2.0 (TID 24) in 17261 ms on 172.16.5.112 (executor driver) (9/16)\n",
      "23/10/27 10:25:56 INFO Executor: Finished task 4.0 in stage 2.0 (TID 21). 2173 bytes result sent to driver\n",
      "23/10/27 10:25:56 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 21) in 17267 ms on 172.16.5.112 (executor driver) (10/16)\n",
      "23/10/27 10:25:56 INFO PythonUDFRunner: Times: total = 3617, boot = 314, init = 234, finish = 3069\n",
      "23/10/27 10:25:56 INFO PythonUDFRunner: Times: total = 3656, boot = 362, init = 266, finish = 3028\n",
      "23/10/27 10:25:56 INFO Executor: Finished task 13.0 in stage 2.0 (TID 30). 2173 bytes result sent to driver\n",
      "23/10/27 10:25:56 INFO Executor: Finished task 11.0 in stage 2.0 (TID 28). 2173 bytes result sent to driver\n",
      "23/10/27 10:25:56 INFO Executor: Finished task 1.0 in stage 2.0 (TID 18). 2173 bytes result sent to driver\n",
      "23/10/27 10:25:56 INFO TaskSetManager: Finished task 11.0 in stage 2.0 (TID 28) in 17285 ms on 172.16.5.112 (executor driver) (11/16)\n",
      "23/10/27 10:25:56 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 18) in 17291 ms on 172.16.5.112 (executor driver) (12/16)\n",
      "23/10/27 10:25:56 INFO TaskSetManager: Finished task 13.0 in stage 2.0 (TID 30) in 17286 ms on 172.16.5.112 (executor driver) (13/16)\n",
      "23/10/27 10:25:56 INFO Executor: Finished task 12.0 in stage 2.0 (TID 29). 2173 bytes result sent to driver\n",
      "23/10/27 10:25:56 INFO TaskSetManager: Finished task 12.0 in stage 2.0 (TID 29) in 17297 ms on 172.16.5.112 (executor driver) (14/16)\n",
      "23/10/27 10:25:56 INFO Executor: Finished task 3.0 in stage 2.0 (TID 20). 2173 bytes result sent to driver\n",
      "23/10/27 10:25:56 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 20) in 17310 ms on 172.16.5.112 (executor driver) (15/16)\n",
      "23/10/27 10:25:56 INFO PythonUDFRunner: Times: total = 3668, boot = 80, init = 192, finish = 3396\n",
      "23/10/27 10:25:56 INFO Executor: Finished task 6.0 in stage 2.0 (TID 23). 2173 bytes result sent to driver\n",
      "23/10/27 10:25:56 INFO TaskSetManager: Finished task 6.0 in stage 2.0 (TID 23) in 17376 ms on 172.16.5.112 (executor driver) (16/16)\n",
      "23/10/27 10:25:56 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "23/10/27 10:25:56 INFO DAGScheduler: ResultStage 2 (save at NativeMethodAccessorImpl.java:0) finished in 17.413 s\n",
      "23/10/27 10:25:56 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/10/27 10:25:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished\n",
      "23/10/27 10:25:56 INFO DAGScheduler: Job 2 finished: save at NativeMethodAccessorImpl.java:0, took 17.425045 s\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "##Load the clean data in postgres\n",
    "\n",
    "new_df.write.format('jdbc').options(url='jdbc:postgresql://localhost:5432/final_project',driver = 'org.postgresql.Driver', dbtable = 'job_description_clean', user=\"postgres\",password=\"postgres\" ).mode('overwrite').save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+--------------+------------+----------+----------------+--------+---------+---------+------------+----------------+----------+--------------------+--------------------+------------+--------------------+--------------------+--------------------+--------------------+-------+\n",
      "|          Job Id|   Experience|Qualifications|Salary Range|  location|         Country|latitude|longitude|Work Type|Company Size|Job Posting Date|Preference|           Job Title|                Role|  Job Portal|     Job Description|              skills|    Responsibilities|             Company|Average|\n",
      "+----------------+-------------+--------------+------------+----------+----------------+--------+---------+---------+------------+----------------+----------+--------------------+--------------------+------------+--------------------+--------------------+--------------------+--------------------+-------+\n",
      "|1089843540111562|5 to 15 Years|        M.Tech|   $59K-$99K|   Douglas|     Isle of Man| 54.2361|  -4.5481|   Intern|       26801|      2022-04-24|    Female|Digital Marketing...|Social Media Manager|    Snagajob|Social Media Mana...|Social media plat...|Manage and grow s...|   Icahn Enterprises|   79.0|\n",
      "| 398454096642776|2 to 12 Years|           BCA|  $56K-$116K|  Ashgabat|    Turkmenistan| 38.9697|  59.5563|   Intern|      100340|      2022-12-19|    Female|       Web Developer|Frontend Web Deve...|    Idealist|Frontend Web Deve...|HTML, CSS, JavaSc...|Design and code u...|PNC Financial Ser...|   86.0|\n",
      "| 481640072963533|0 to 12 Years|           PhD|  $61K-$104K|     Macao|Macao SAR, China| 22.1987| 113.5439|Temporary|       84525|      2022-09-14|      Male|  Operations Manager|Quality Control M...|Jobs2Careers|Quality Control M...|Quality control p...|Establish and enf...|United Services A...|   82.5|\n",
      "| 688192671473044|4 to 11 Years|           PhD|   $65K-$91K|Porto-Novo|           Benin|  9.3077|   2.3158|Full-Time|      129896|      2023-02-25|    Female|    Network Engineer|Wireless Network ...|    FlexJobs|Wireless Network ...|Wireless network ...|Design, configure...|                Hess|   78.0|\n",
      "| 117057806156508|1 to 12 Years|           MBA|   $64K-$87K|  Santiago|           Chile|-35.6751| -71.5429|   Intern|       53944|      2022-10-11|    Female|       Event Manager|  Conference Manager|Jobs2Careers|A Conference Mana...|Event planning Co...|Specialize in con...|        Cairn Energy|   75.5|\n",
      "+----------------+-------------+--------------+------------+----------+----------------+--------+---------+---------+------------+----------------+----------+--------------------+--------------------+------------+--------------------+--------------------+--------------------+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
